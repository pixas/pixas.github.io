@inproceedings{zhang2023cab,
  title={Cab: comprehensive attention benchmarking on long sequence modeling},
  author={Zhang, Jun and Jiang, Shuyang and Feng, Jiangtao and Zheng, Lin and Kong, Lingpeng},
  booktitle={International Conference on Machine Learning},
  pages={41194--41218},
  year={2023},
  organization={PMLR}
}

@inproceedings{jiang2023attentive,
  title={Attentive Multi-Layer Perceptron for Non-autoregressive Generation},
  author={Jiang, Shuyang and Zhang, Jun and Feng, Jiangtao and Zheng, Lin and Kong, Lingpeng},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={612--629},
  year={2023},
  organization={Springer}
}

@inproceedings{liao2023self,
  title={Self-Improvement of Non-autoregressive Model via Sequence-Level Distillation},
  author={Liao, Yusheng and Jiang, Shuyang and Li, Yiqi and Wang, Yu and Wang, Yanfeng},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={14202--14212},
  year={2023}
}

